# 文件去重功能说明

## 功能概述

Mana 支持智能去重功能，在上传账单文件时自动检测并阻止重复上传**完全相同的文件**，避免重复导入相同的数据。

## 工作原理

### 去重策略

系统使用**文件内容哈希**来判断文件是否重复：

1. **计算文件哈希** - 使用 SHA-256 算法计算文件内容的哈希值
2. **数据库查询** - 检查数据库中是否已存在相同哈希的文件
3. **阻止重复** - 如果文件已存在，返回错误提示并拒绝上传

**示例**：
```
文件 A: alipay-2024-01.csv (内容哈希: abc123...)
文件 B: alipay-2024-01.csv (内容哈希: abc123...)  ← 重复，拒绝上传

文件 C: alipay-backup.csv (内容哈希: abc123...)  ← 内容相同，拒绝上传
文件 D: alipay-2024-02.csv (内容哈希: def456...)  ← 内容不同，允许上传
```

### 去重流程

```
用户上传文件
  ↓
计算文件哈希（SHA-256）
  ↓
【去重检查】
  ├─ 查询数据库中是否存在相同哈希
  ├─ 如果存在：返回错误，拒绝上传
  └─ 如果不存在：继续正常处理
  ↓
解析账单数据
  ↓
保存到数据库（包含文件哈希）
```

## 使用场景

### 场景 1：重复上传相同文件

**问题**：用户不小心上传了相同的账单文件

**结果**：
- 系统检测到文件哈希相同
- 返回错误提示："该文件已于 2024-01-15 上传"
- 不会保存任何数据

### 场景 2：不同文件名，相同内容

**问题**：用户重命名文件后再次上传

**示例**：
- 原文件：`alipay-2024-01.csv`
- 新文件：`alipay-backup.csv`（内容完全相同）

**结果**：
- 系统检测到内容哈希相同
- 提示："检测到相同内容的文件（原文件名：alipay-2024-01.csv）"
- 拒绝上传

### 场景 3：不同文件，不同内容

**问题**：用户上传不同时间段的账单

**示例**：
- 文件 A：1月账单（100条交易）
- 文件 B：2月账单（150条交易）

**结果**：
- 文件内容不同，哈希值不同
- 允许上传
- 即使有相同的交易记录也不影响

## API 响应

### 成功上传

```json
{
  "uploadId": "upload-1234567890-abc123",
  "success": true,
  "beancountContent": "...",
  "stats": {
    "totalRecords": 150,
    "validRecords": 150,
    "invalidRecords": 0
  }
}
```

### 文件重复

```json
{
  "error": "文件已存在",
  "message": "该文件已于 2024-01-15 上传",
  "existingUpload": {
    "id": "upload-1234567890-xyz789",
    "filename": "alipay-2024-01.csv",
    "uploadDate": "2024-01-15",
    "transactionCount": 150,
    "totalAmount": 5000.00
  }
}
```

## 技术实现

### 核心函数

#### 1. `calculateFileHash(file)`

计算文件的 SHA-256 哈希值：

```typescript
const fileHash = await calculateFileHash(file);
// 返回: "a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8c9d0e1f2"
```

#### 2. `checkFileDuplicate(db, fileHash)`

检查文件是否已存在：

```typescript
const duplicate = await checkFileDuplicate(db, fileHash);
if (duplicate) {
  // 文件已存在
  console.log(`文件已于 ${duplicate.upload_date} 上传`);
}
```

### 数据库设计

```sql
CREATE TABLE uploads (
  id TEXT PRIMARY KEY,
  original_filename TEXT NOT NULL,
  file_hash TEXT,  -- SHA-256 哈希值
  ...
);

CREATE INDEX idx_uploads_file_hash ON uploads(file_hash);
```

### 性能考虑

- **哈希计算**：SHA-256 算法，对于 10MB 文件约需 100-200ms
- **数据库查询**：使用索引，查询时间 <10ms
- **总开销**：约 100-300ms，对用户体验影响很小

## 关键特性

### ✅ 准确性高
- 基于文件内容，不受文件名影响
- 即使文件名不同，内容相同也能识别

### ✅ 性能优秀
- 不需要遍历所有历史交易记录
- 使用数据库索引，查询速度快

### ✅ 用户友好
- 提供详细的错误提示
- 显示原文件的上传日期和统计信息

### ⚠️ 注意事项

1. **文件内容必须完全相同**
   - 即使只有一个字符不同，也会被认为是不同文件
   - 例如：导出时间戳不同会导致哈希不同

2. **允许相同交易记录**
   - 不同文件可以包含相同的交易记录
   - 例如：支付宝账单和微信账单可能有相同的商户名称

3. **不支持强制重新上传**
   - 目前如果文件重复，无法强制上传
   - 未来可能添加此功能

## 测试覆盖

### 测试用例（6个）

1. **哈希格式化测试**（2个）
   - 格式化长哈希为短格式
   - 保持短哈希不变

2. **哈希验证测试**（4个）
   - 验证有效的 SHA-256 哈希
   - 拒绝无效长度的哈希
   - 拒绝包含非十六进制字符的哈希
   - 接受大小写混合的哈希

**测试结果**：137 个测试用例全部通过 ✅

## 常见问题

### Q1: 为什么我的文件被识别为重复？

**A**: 系统基于文件内容的 SHA-256 哈希判断重复。如果文件内容完全相同（包括空格、换行等），就会被识别为重复。

### Q2: 我重命名了文件，为什么还是提示重复？

**A**: 系统不看文件名，只看文件内容。即使文件名不同，只要内容相同就会被识别为重复。

### Q3: 我想上传同一时间段的支付宝和微信账单，会被拒绝吗？

**A**: 不会。支付宝和微信的账单文件格式不同，内容也不同，所以哈希值不同，可以正常上传。

### Q4: 如果我确实需要重新上传相同文件怎么办？

**A**: 目前系统不支持强制重新上传。如果确实需要，可以：
1. 先删除历史记录
2. 或者联系开发者添加"强制重新上传"功能

### Q5: 文件去重会影响上传速度吗？

**A**: 影响很小。计算 SHA-256 哈希对于 10MB 文件约需 100-200ms，数据库查询约需 10ms，总开销约 100-300ms。

## 与旧版本的区别

### 旧版本（交易记录去重）

- 基于交易日期、金额、描述判断重复
- 需要遍历所有历史交易记录
- 会过滤掉重复的交易记录
- 不同文件的相同交易会被去重

### 新版本（文件去重）

- 基于文件内容哈希判断重复
- 只需查询数据库索引
- 阻止上传完全相同的文件
- 允许不同文件包含相同交易

### 为什么改变？

1. **更符合用户需求** - 用户希望避免重复上传文件，而不是去重交易记录
2. **性能更好** - 不需要遍历所有历史交易
3. **逻辑更简单** - 文件级别的去重更直观
4. **更灵活** - 允许从不同来源导入相同时间段的账单

---

**更新时间**: 2026-01-31
**版本**: v2.0.0 (文件去重)
